#!/usr/bin/env python
"""
Tushareæ•°æ®è·å–å™¨
ä½¿ç”¨Tushareæ¥å£è·å–2024å¹´ä»¥æ¥çš„Aè‚¡æ—¥Kçº¿æ•°æ®
"""
import os
import sys
import time
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Tuple
from tqdm import tqdm
from multiprocessing import Pool, cpu_count, Manager
from functools import partial
import inspect

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import tushare as ts
except ImportError:
    print("é”™è¯¯: æ— æ³•å¯¼å…¥tushareï¼Œè¯·å…ˆå®‰è£…: pip install tushare")
    sys.exit(1)

try:
    import akshare as ak
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥akshareï¼Œå°†æ— æ³•ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    ak = None


def debug_print(message: str, show_line_number: bool = False):
    """
    è°ƒè¯•æ‰“å°å‡½æ•°ï¼Œå¯é€‰æ‹©æ˜¾ç¤ºå½“å‰è¡Œå·

    Args:
        message: è¦æ‰“å°çš„æ¶ˆæ¯
        show_line_number: æ˜¯å¦æ˜¾ç¤ºè¡Œå·
    """
    if show_line_number:
        frame = inspect.currentframe().f_back
        filename = os.path.basename(frame.f_code.co_filename)
        line_number = frame.f_lineno
        print(f"[{filename}:{line_number}] {message}")
    else:
        print(message)


class TokenWorker:
    """ç”¨äºå¹¶è¡Œå¤„ç†çš„Tokenå·¥ä½œå™¨ï¼ˆè½»é‡åŒ–ï¼‰"""

    def __init__(self, token: str, data_dir: str, adjust: str, start_date: str, today: str, verbose: bool = False):
        """
        åˆå§‹åŒ–Tokenå·¥ä½œå™¨

        Args:
            token: Tushare API token
            data_dir: æ•°æ®ç›®å½•
            adjust: å¤æƒæ–¹å¼
            start_date: å¼€å§‹æ—¥æœŸ
            today: ä»Šå¤©æ—¥æœŸ
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯ï¼ˆå¹¶è¡Œæ¨¡å¼ä¸‹é»˜è®¤Falseï¼‰
        """
        self.token = token
        self.data_dir = data_dir
        self.daily_dir = os.path.join(data_dir, "daily")
        self.adjust = adjust
        self.start_date = start_date
        self.today = today
        self.verbose = verbose

        # åˆå§‹åŒ–Tushare API
        ts.set_token(token)
        self.pro = ts.pro_api()

    def check_data_status(self, stock_code: str, end_date: str = None) -> Dict:
        """æ£€æŸ¥è‚¡ç¥¨æ•°æ®çš„å½“å‰çŠ¶æ€

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            end_date: ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œå¦‚æœæä¾›ï¼Œå°†ä¸ç°æœ‰æ•°æ®æ¯”è¾ƒ
        """
        status = {
            'exists': False,
            'latest_date': None,
            'total_records': 0,
            'needs_update': False
        }

        filename = f"{stock_code}_daily.csv"
        filepath = os.path.join(self.daily_dir, filename)

        if os.path.exists(filepath):
            try:
                df = pd.read_csv(filepath)
                df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
                status['exists'] = True
                status['total_records'] = len(df)
                status['latest_date'] = df['trade_date'].max().strftime('%Y%m%d')

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if end_date:
                    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç»“æŸæ—¥æœŸï¼Œæ£€æŸ¥ç°æœ‰æ•°æ®æ˜¯å¦å·²ç»è¦†ç›–åˆ°è¯¥æ—¥æœŸ
                    if status['latest_date'] >= end_date:
                        # ç°æœ‰æ•°æ®å·²ç»åŒ…å«æˆ–è¶…è¿‡ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œæ— éœ€æ›´æ–°
                        status['needs_update'] = False
                        if self.verbose:
                            debug_print(f"âœ“ {stock_code} æ•°æ®å·²è¦†ç›–è‡³ {status['latest_date']}ï¼Œæ— éœ€æ›´æ–°åˆ° {end_date}", show_line_number=True)
                    else:
                        # ç°æœ‰æ•°æ®æ²¡æœ‰è¦†ç›–åˆ°ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œéœ€è¦æ›´æ–°
                        status['needs_update'] = True
                        if self.verbose:
                            debug_print(f"ğŸ“… {stock_code} æ•°æ®åªåˆ° {status['latest_date']}ï¼Œéœ€è¦æ›´æ–°åˆ° {end_date}", show_line_number=True)
                else:
                    # é»˜è®¤é€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°åˆ°æ˜¨å¤©
                    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
                    if status['latest_date'] < yesterday:
                        status['needs_update'] = True
            except Exception as e:
                pass

        if not status['exists']:
            status['needs_update'] = True

        return status

    def calculate_update_range(self, stock_code: str) -> tuple[str, str]:
        """è®¡ç®—éœ€è¦æ›´æ–°çš„æ—¥æœŸèŒƒå›´"""
        status = self.check_data_status(stock_code)

        if not status['exists']:
            return self.start_date, self.today

        latest_date = status['latest_date']
        if latest_date >= self.today:
            return None, None

        next_date = (datetime.strptime(latest_date, '%Y%m%d') + timedelta(days=1)).strftime('%Y%m%d')
        return next_date, self.today

    def fetch_daily_data(self, stock_code: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """è·å–å•åªè‚¡ç¥¨çš„æ—¥Kçº¿æ•°æ®"""
        try:
            df = self.pro.daily(
                ts_code=stock_code,
                start_date=start_date,
                end_date=end_date,
                adj=self.adjust,
                fields='ts_code,trade_date,open,high,low,close,pre_close,change,pct_chg,vol,amount'
            )

            if df is None or df.empty:
                return df

            df = df.sort_values('trade_date')

            if 'pct_chg' not in df.columns or df['pct_chg'].isnull().all():
                df['pct_chg'] = ((df['close'] - df['pre_close']) / df['pre_close'] * 100).round(2)

            df['change'] = (df['close'] - df['pre_close']).round(2)
            df['vol'] = (df['vol'] / 100).round(0)
            df['amount'] = (df['amount'] / 10000).round(2)

            return df

        except Exception as e:
            return None

    def merge_daily_data(self, stock_code: str, new_df: pd.DataFrame) -> bool:
        """åˆå¹¶æ¯æ—¥æ•°æ®"""
        filename = f"{stock_code}_daily.csv"
        filepath = os.path.join(self.daily_dir, filename)

        try:
            new_df['trade_date'] = pd.to_datetime(new_df['trade_date'], format='%Y%m%d')

            if os.path.exists(filepath):
                existing_df = pd.read_csv(filepath)
                existing_df['trade_date'] = pd.to_datetime(existing_df['trade_date'], format='%Y%m%d')

                combined = pd.concat([existing_df, new_df], ignore_index=True)
                combined = combined.drop_duplicates(subset=['trade_date'], keep='last')
                combined = combined.sort_values('trade_date')
            else:
                combined = new_df

            combined['trade_date'] = combined['trade_date'].dt.strftime('%Y%m%d')
            combined.to_csv(filepath, index=False, encoding='utf-8-sig')
            return True

        except Exception as e:
            return False

    def process_single_stock(self, stock_code: str, end_date: str = None) -> Tuple[str, bool, int]:
        """å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´æ›´æ–°æµç¨‹

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            end_date: ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸ
        """
        try:
            status = self.check_data_status(stock_code, end_date)

            if status['needs_update']:
                if end_date:
                    # ç”¨æˆ·æŒ‡å®šäº†ç»“æŸæ—¥æœŸï¼Œä½¿ç”¨ç”¨æˆ·çš„ç»“æŸæ—¥æœŸ
                    start_date, calculated_end_date = self.calculate_update_range(stock_code)
                    # å¦‚æœè®¡ç®—å‡ºçš„ç»“æŸæ—¥æœŸè¶…è¿‡äº†ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„
                    actual_end_date = min(calculated_end_date, end_date) if calculated_end_date > end_date else calculated_end_date
                else:
                    # é»˜è®¤é€»è¾‘
                    start_date, actual_end_date = self.calculate_update_range(stock_code)

                if start_date is None:
                    return stock_code, True, 0
                df = self.fetch_daily_data(stock_code, start_date, actual_end_date)
                if df is None:
                    if self.verbose:
                        debug_print(f"âœ— {stock_code} æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡å¤„ç†", show_line_number=True)
                    return stock_code, False, 0
                elif df.empty:
                    if self.verbose:
                        debug_print(f"âœ— {stock_code} æ²¡æœ‰æ–°æ•°æ®ï¼Œè·³è¿‡å¤„ç†", show_line_number=True)
                    return stock_code, True, 0

                success = self.merge_daily_data(stock_code, df)
                records_added = len(df) if success else 0
                if self.verbose:
                    if success:
                        debug_print(f"âœ“ {stock_code} æ›´æ–°æˆåŠŸï¼Œæ–°å¢ {records_added} æ¡è®°å½•", show_line_number=True)
                    else:
                        debug_print(f"âœ— {stock_code} æ•°æ®åˆå¹¶å¤±è´¥", show_line_number=True)
                return stock_code, success, records_added
            else:
                return stock_code, True, 0

        except Exception as e:
            if self.verbose:
                import traceback
                tb = traceback.extract_tb(e.__traceback__)
                if tb:
                    filename, line_number, func_name, text = tb[-1]
                    print(f"âœ— å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™ [{filename}:{line_number}]: {e}")
                else:
                    print(f"âœ— å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return stock_code, False, 0

class TushareDataFetcher:
    """Tushareæ•°æ®è·å–å™¨"""

    def __init__(self, token: str, data_dir: str = ".", adjust: str = "qfq", tokens: List[str] = None, verbose: bool = True):
        """
        åˆå§‹åŒ–Tushareæ•°æ®è·å–å™¨

        Args:
            token: Tushare API tokenï¼ˆä¸»è¦tokenï¼‰
            data_dir: æ•°æ®å­˜å‚¨ç›®å½•
            adjust: å¤æƒæ–¹å¼ï¼Œ'qfq'-å‰å¤æƒï¼Œ'hfq'-åå¤æƒï¼Œ''-ä¸å¤æƒ
            tokens: å¤šä¸ªtokenåˆ—è¡¨ï¼Œç”¨äºå¹¶è¡Œå¤„ç†é¿å…é™æµ
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†ä¿¡æ¯
        """
        self.token = token
        self.tokens = tokens or [token]  # å¦‚æœæ²¡æœ‰æä¾›å¤šä¸ªtokenï¼Œä½¿ç”¨å•ä¸ªtoken
        self.data_dir = data_dir
        self.daily_dir = os.path.join(data_dir, "daily")
        self.adjust = adjust  # å¤æƒæ–¹å¼
        self.verbose = verbose  # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯

        # åˆ›å»ºç›®å½•
        os.makedirs(self.daily_dir, exist_ok=True)

        # åˆå§‹åŒ–å¤šä¸ªTushare APIå®ä¾‹
        self.pro_instances = []
        for i, tk in enumerate(self.tokens):
            ts.set_token(tk)
            pro = ts.pro_api()
            self.pro_instances.append(pro)
            if verbose:
                print(f"âœ“ åˆå§‹åŒ–Token {i+1}/{len(self.tokens)}: {tk[:10]}...")

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªtokenä½œä¸ºé»˜è®¤å®ä¾‹
        self.pro = self.pro_instances[0]

        # è®¾ç½®æ—¶é—´èŒƒå›´
        self.start_date = "20240101"  # ä»2024å¹´å¼€å§‹
        self.today = datetime.now().strftime('%Y%m%d')

        adjust_desc = {"qfq": "å‰å¤æƒ", "hfq": "åå¤æƒ", "": "ä¸å¤æƒ"}.get(adjust, "æœªçŸ¥")
        if verbose:
            debug_print(f"âœ“ Tushare APIåˆå§‹åŒ–å®Œæˆï¼Œ{len(self.tokens)}ä¸ªtokenï¼Œæ•°æ®å°†ä¿å­˜åˆ°: {self.data_dir}ï¼Œå¤æƒæ–¹å¼: {adjust_desc}", show_line_number=True)

    def get_stock_list(self, force_refresh: bool = False) -> List[str]:
        """è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ”¯æŒæœ¬åœ°ç¼“å­˜ï¼‰

        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜ï¼Œå¿½ç•¥æœ¬åœ°æ–‡ä»¶
        """
        # å®šä¹‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
        cache_file = os.path.join(self.data_dir, "stock_list_cache.txt")

        # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸å¼ºåˆ¶åˆ·æ–°
        if not force_refresh and os.path.exists(cache_file):
            try:
                print("æ­£åœ¨ä»æœ¬åœ°ç¼“å­˜è¯»å–è‚¡ç¥¨åˆ—è¡¨...")
                with open(cache_file, 'r', encoding='utf-8') as f:
                    stock_codes = [line.strip() for line in f if line.strip()]

                if stock_codes:
                    debug_print(f"âœ“ ä»ç¼“å­˜è¯»å–æˆåŠŸï¼Œå…± {len(stock_codes)} åªAè‚¡è‚¡ç¥¨", show_line_number=True)
                    return stock_codes
                else:
                    debug_print("âš ï¸ ç¼“å­˜æ–‡ä»¶ä¸ºç©ºï¼Œå°†é‡æ–°è·å–", show_line_number=True)

            except Exception as e:
                print(f"âš ï¸ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°†é‡æ–°è·å–")

        # ä»APIè·å–è‚¡ç¥¨åˆ—è¡¨
        try:
            print("æ­£åœ¨è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆTushareï¼‰...")

            # è·å–æ²ªæ·±Aè‚¡åŸºæœ¬ä¿¡æ¯
            df = self.pro.stock_basic(
                exchange='',
                list_status='L',  # L-ä¸Šå¸‚ï¼ŒD-é€€å¸‚ï¼ŒP-æš‚åœä¸Šå¸‚
                fields='ts_code,symbol,name,area,industry,list_date'
            )

            stock_codes = df['ts_code'].tolist()
            debug_print(f"âœ“ Tushareè·å–æˆåŠŸï¼Œå…± {len(stock_codes)} åªAè‚¡è‚¡ç¥¨", show_line_number=True)

            # ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
            try:
                with open(cache_file, 'w', encoding='utf-8') as f:
                    for code in stock_codes:
                        f.write(f"{code}\n")
                debug_print(f"âœ“ è‚¡ç¥¨åˆ—è¡¨å·²ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶: {cache_file}", show_line_number=True)
            except Exception as e:
                debug_print(f"âš ï¸ ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}ï¼ˆä¸å½±å“ç¨‹åºè¿è¡Œï¼‰", show_line_number=True)

            return stock_codes

        except Exception as e:
            print(f"âœ— Tushareè·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")

            # å°è¯•ä½¿ç”¨akshareä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            if ak is not None:
                try:
                    print("æ­£åœ¨å°è¯•ä½¿ç”¨akshareè·å–è‚¡ç¥¨åˆ—è¡¨...")
                    stock_list = ak.stock_info_a_code_name()
                    stock_codes = stock_list['code'].tolist()

                    # è½¬æ¢ä¸ºtushareæ ¼å¼ï¼ˆæ·»åŠ .SH/.SZ/.BJåç¼€ï¼‰
                    converted_codes = []
                    for code in stock_codes:
                        code_int = int(code)
                        if (code.startswith('0') and 1 <= code_int <= 4999) or \
                           (code.startswith('3') and 300000 <= code_int <= 399999):
                            converted_codes.append(f"{code}.SZ")  # æ·±åœ³äº¤æ˜“æ‰€
                        elif (code.startswith('6') and 600000 <= code_int <= 699999):
                            converted_codes.append(f"{code}.SH")  # ä¸Šæµ·äº¤æ˜“æ‰€
                        elif (code.startswith('8') and 830000 <= code_int <= 879999) or \
                             (code.startswith('4') and 430000 <= code_int <= 479999) or \
                             (code.startswith('9') and 920000 <= code_int <= 999999):
                            converted_codes.append(f"{code}.BJ")  # åŒ—äº¬äº¤æ˜“æ‰€
                        elif code.startswith('9') and 900000 <= code_int <= 919999:
                            converted_codes.append(f"{code}.SH")  # ä¸Šæµ·Bè‚¡
                        else:
                            converted_codes.append(f"{code}.SH")  # é»˜è®¤SH

                    print(f"âœ“ akshareå¤‡ç”¨è·å–æˆåŠŸï¼Œå…± {len(converted_codes)} åªAè‚¡è‚¡ç¥¨")

                    # ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
                    try:
                        with open(cache_file, 'w', encoding='utf-8') as f:
                            for code in converted_codes:
                                f.write(f"{code}\n")
                        print(f"âœ“ è‚¡ç¥¨åˆ—è¡¨å·²ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶: {cache_file}")
                    except Exception as e:
                        print(f"âš ï¸ ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}ï¼ˆä¸å½±å“ç¨‹åºè¿è¡Œï¼‰")

                    return converted_codes

                except Exception as e2:
                    print(f"âœ— akshareå¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
            else:
                print("âœ— akshareä¸å¯ç”¨ï¼Œæ— å¤‡ç”¨æ–¹æ¡ˆ")

            print("âœ— æ‰€æœ‰è·å–è‚¡ç¥¨åˆ—è¡¨çš„æ–¹æ³•éƒ½å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
            sys.exit(1)

    def check_data_status(self, stock_code: str, end_date: str = None) -> Dict:
        """
        æ£€æŸ¥è‚¡ç¥¨æ•°æ®çš„å½“å‰çŠ¶æ€

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼ä¸ºXXXXXX.SHæˆ–XXXXXX.SZ
            end_date: ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œå¦‚æœæä¾›ï¼Œå°†ä¸ç°æœ‰æ•°æ®æ¯”è¾ƒ

        Returns:
            çŠ¶æ€ä¿¡æ¯å­—å…¸
        """
        status = {
            'exists': False,
            'latest_date': None,
            'total_records': 0,
            'needs_update': False
        }

        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        filename = f"{stock_code}_daily.csv"
        filepath = os.path.join(self.daily_dir, filename)

        if os.path.exists(filepath):
            try:
                df = pd.read_csv(filepath)
                df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
                status['exists'] = True
                status['total_records'] = len(df)
                status['latest_date'] = df['trade_date'].max().strftime('%Y%m%d')

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if end_date:
                    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç»“æŸæ—¥æœŸï¼Œæ£€æŸ¥ç°æœ‰æ•°æ®æ˜¯å¦å·²ç»è¦†ç›–åˆ°è¯¥æ—¥æœŸ
                    if status['latest_date'] >= end_date:
                        # ç°æœ‰æ•°æ®å·²ç»åŒ…å«æˆ–è¶…è¿‡ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œæ— éœ€æ›´æ–°
                        status['needs_update'] = False
                        if self.verbose:
                            debug_print(f"âœ“ {stock_code} æ•°æ®å·²è¦†ç›–è‡³ {status['latest_date']}ï¼Œæ— éœ€æ›´æ–°åˆ° {end_date}", show_line_number=True)
                    else:
                        # ç°æœ‰æ•°æ®æ²¡æœ‰è¦†ç›–åˆ°ç”¨æˆ·æŒ‡å®šçš„ç»“æŸæ—¥æœŸï¼Œéœ€è¦æ›´æ–°
                        status['needs_update'] = True
                        if self.verbose:
                            debug_print(f"ğŸ“… {stock_code} æ•°æ®åªåˆ° {status['latest_date']}ï¼Œéœ€è¦æ›´æ–°åˆ° {end_date}", show_line_number=True)
                else:
                    # é»˜è®¤é€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°åˆ°æ˜¨å¤©
                    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
                    if status['latest_date'] < yesterday:
                        status['needs_update'] = True
            except Exception as e:
                print(f"è¯»å–æ•°æ®å¤±è´¥ {stock_code}: {e}")

        # æ–°è‚¡ç¥¨éœ€è¦åˆå§‹åŒ–æ•°æ®
        if not status['exists']:
            status['needs_update'] = True

        return status

    def calculate_update_range(self, stock_code: str) -> tuple[str, str]:
        """
        è®¡ç®—éœ€è¦æ›´æ–°çš„æ—¥æœŸèŒƒå›´

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            (start_date, end_date) æ ¼å¼: YYYYMMDD
        """
        status = self.check_data_status(stock_code)

        if not status['exists']:
            # æ–°è‚¡ç¥¨ï¼Œä»2024å¹´å¼€å§‹
            return self.start_date, self.today

        latest_date = status['latest_date']
        if latest_date >= self.today:
            # æ•°æ®å·²æ˜¯æœ€æ–°
            return None, None

        # ä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹æ›´æ–°åˆ°ä»Šå¤©
        next_date = (datetime.strptime(latest_date, '%Y%m%d') + timedelta(days=1)).strftime('%Y%m%d')
        return next_date, self.today

    def fetch_daily_data(self, stock_code: str, start_date: str, end_date: str, max_retries: int = 3) -> Optional[pd.DataFrame]:
        """
        è·å–å•åªè‚¡ç¥¨çš„æ—¥Kçº¿æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼ä¸ºXXXXXX.SHæˆ–XXXXXX.SZ
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            æ—¥Kçº¿æ•°æ®DataFrame
        """
        import time

        for attempt in range(max_retries):
            try:
                # è°ƒç”¨Tushareæ—¥çº¿è¡Œæƒ…æ¥å£
                df = self.pro.daily(
                    ts_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    adj=self.adjust,  # å¤æƒæ–¹å¼
                    fields='ts_code,trade_date,open,high,low,close,pre_close,change,pct_chg,vol,amount'
                )

                if df is None or df.empty:
                    if self.verbose and attempt == max_retries - 1:
                        print(f"âš ï¸ {stock_code} APIè¿”å›ç©ºæ•°æ® ({start_date} è‡³ {end_date})")
                    return None

                # æ•°æ®é¢„å¤„ç†
                df = df.sort_values('trade_date')  # æŒ‰æ—¥æœŸæ’åº

                # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æœAPIæ²¡æœ‰æä¾›ï¼‰
                if 'pct_chg' not in df.columns or df['pct_chg'].isnull().all():
                    df['pct_chg'] = ((df['close'] - df['pre_close']) / df['pre_close'] * 100).round(2)

                # è®¡ç®—æ¶¨è·Œé¢
                df['change'] = (df['close'] - df['pre_close']).round(2)

                # æˆäº¤é‡è½¬æ¢ä¸ºæ‰‹ï¼ˆAPIè¿”å›çš„æ˜¯è‚¡ï¼‰
                df['vol'] = (df['vol'] / 100).round(0)  # è½¬æ¢ä¸ºæ‰‹

                # æˆäº¤é¢è½¬æ¢ä¸ºä¸‡å…ƒ
                df['amount'] = (df['amount'] / 10000).round(2)  # è½¬æ¢ä¸ºä¸‡å…ƒ

                return df

            except Exception as e:
                if attempt < max_retries - 1:
                    # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•°é€€é¿: 2s, 4s, 6s...
                    if self.verbose:
                        print(f"âš ï¸ {stock_code} ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•: {str(e)[:50]}...")
                    time.sleep(wait_time)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    if self.verbose:
                        print(f"âœ— {stock_code} è·å–å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {str(e)[:50]}...")
                    return None

    def update_daily_data(self, stock_code: str) -> bool:
        """æ›´æ–°å•åªè‚¡ç¥¨çš„æ¯æ—¥æ•°æ®"""
        start_date, end_date = self.calculate_update_range(stock_code)

        if start_date is None:
            if self.verbose:
                debug_print(f"âœ“ {stock_code} æ¯æ—¥æ•°æ®å·²æ˜¯æœ€æ–°", show_line_number=True)
            return True

        if self.verbose:
            debug_print(f"æ›´æ–° {stock_code} æ¯æ—¥æ•°æ®: {start_date} è‡³ {end_date}", show_line_number=True)

        try:
            # è·å–æ–°æ•°æ®
            df = self.fetch_daily_data(stock_code, start_date, end_date)

            if df is None or df.empty:
                if self.verbose:
                    debug_print(f"âœ— {stock_code} æ— æ–°æ•°æ®", show_line_number=True)
                return False

            # åˆå¹¶å†å²æ•°æ®
            success = self._merge_daily_data(stock_code, df)
            if success:
                debug_print(f"âœ“ {stock_code} æ›´æ–°æˆåŠŸï¼Œæ–°å¢ {len(df)} æ¡è®°å½•", show_line_number=self.verbose)
            return success

        except Exception as e:
            if self.verbose:
                print(f"âœ— æ›´æ–° {stock_code} æ¯æ—¥æ•°æ®å¤±è´¥: {e}")
            return False

    def process_single_stock(self, stock_code: str) -> Tuple[str, bool, int]:
        """
        å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´æ›´æ–°æµç¨‹

        Returns:
            (stock_code, success, records_added)
        """
        try:
            # æ£€æŸ¥æ•°æ®çŠ¶æ€
            status = self.check_data_status(stock_code)

            if status['needs_update']:
                success = self.update_daily_data(stock_code)
                records_added = len(self._get_new_records_count(stock_code)) if success else 0
                return stock_code, success, records_added
            else:
                return stock_code, True, 0  # è·³è¿‡ä½†ç®—æˆåŠŸ

        except Exception as e:
            if self.verbose:
                import traceback
                tb = traceback.extract_tb(e.__traceback__)
                if tb:
                    filename, line_number, func_name, text = tb[-1]
                    print(f"âœ— å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™ [{filename}:{line_number}]: {e}")
                else:
                    print(f"âœ— å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
            return stock_code, False, 0

    def _get_new_records_count(self, stock_code: str) -> pd.DataFrame:
        """è·å–æœ€æ–°è·å–çš„æ•°æ®é‡ï¼ˆç”¨äºç»Ÿè®¡ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥è®°å½•æœ€æ–°è·å–çš„æ•°æ®æ¡æ•°
            # ç”±äºåˆå¹¶é€»è¾‘å¤æ‚ï¼Œè¿™é‡Œç®€åŒ–è¿”å›ç©ºDataFrame
            return pd.DataFrame()
        except:
            return pd.DataFrame()

    def update_stocks_parallel(self, stock_codes: List[str], max_workers: int = None, force_verbose: bool = False, end_date: str = None) -> Dict:
        """
        å¹¶å‘æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆä½¿ç”¨å¤šä¸ªtokené¿å…APIé™æµï¼‰

        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            max_workers: æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°çš„ä¸€åŠ

        Returns:
            æ›´æ–°ç»Ÿè®¡ç»“æœ
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed

        if max_workers is None:
            # é™ä½å¹¶å‘æ•°ï¼Œé¿å…APIé™æµã€‚Tushareå…è´¹è´¦æˆ·é™åˆ¶ä¸¥æ ¼
            max_workers = min(2, len(self.tokens))  # æœ€å¤šä½¿ç”¨2ä¸ªçº¿ç¨‹ï¼Œæˆ–è€…tokenæ•°é‡

        print(f"ğŸ¯ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹ï¼Œ{len(self.tokens)} ä¸ªtokenå¹¶å‘å¤„ç†")

        stats = {
            'total_stocks': len(stock_codes),
            'success': 0,
            'fail': 0,
            'skipped': 0,
            'new_records': 0
        }

        # ä¸ºæ¯ä¸ªtokenåˆ›å»ºfetcherå®ä¾‹ï¼ˆç®€åŒ–ç‰ˆï¼ŒåªåŒ…å«å¿…è¦æ–¹æ³•ï¼‰
        # å¦‚æœå¼ºåˆ¶è¦æ±‚verboseï¼Œå³ä½¿åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ä¹Ÿæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        worker_verbose = force_verbose if force_verbose else False
        token_fetchers = []
        for i, token in enumerate(self.tokens):
            fetcher = TokenWorker(token, self.data_dir, self.adjust, self.start_date, self.today, verbose=worker_verbose)
            token_fetchers.append(fetcher)

        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # é¢„å…ˆæ£€æŸ¥å“ªäº›è‚¡ç¥¨éœ€è¦æ›´æ–°ï¼Œé¿å…åˆ›å»ºä¸å¿…è¦çš„çº¿ç¨‹
            stocks_to_update = []
            skipped_stocks = []

            print("ğŸ” æ­£åœ¨æ£€æŸ¥æ•°æ®æ›´æ–°çŠ¶æ€...")
            for stock_code in stock_codes:
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶workeræ¥æ£€æŸ¥çŠ¶æ€ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªtokenï¼‰
                temp_worker = token_fetchers[0]
                status = temp_worker.check_data_status(stock_code, end_date)
                if status['needs_update']:
                    stocks_to_update.append(stock_code)
                else:
                    skipped_stocks.append(stock_code)
                    stats['skipped'] += 1
                    if worker_verbose:
                        if end_date:
                            debug_print(f"â­ï¸ {stock_code} æ•°æ®å·²è¦†ç›–è‡³ {status['latest_date']}ï¼Œæ— éœ€æ›´æ–°åˆ° {end_date}", show_line_number=True)
                        else:
                            debug_print(f"â­ï¸ {stock_code} æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡æ›´æ–°", show_line_number=True)

            print(f"ğŸ“Š æ£€æŸ¥å®Œæˆ: {len(stocks_to_update)} åªè‚¡ç¥¨éœ€è¦æ›´æ–°ï¼Œ{len(skipped_stocks)} åªå·²è·³è¿‡")

            # åªä¸ºéœ€è¦æ›´æ–°çš„è‚¡ç¥¨æäº¤ä»»åŠ¡
            future_to_stock = {}
            for i, stock_code in enumerate(stocks_to_update):
                # è½®æµä½¿ç”¨ä¸åŒçš„token
                token_index = i % len(token_fetchers)
                fetcher = token_fetchers[token_index]

                future = executor.submit(fetcher.process_single_stock, stock_code, end_date)
                future_to_stock[future] = stock_code

                # åœ¨æäº¤ä»»åŠ¡ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                if (i + 1) % max_workers == 0:
                    time.sleep(1)  # æ¯æ‰¹ä»»åŠ¡åæš‚åœ1ç§’

            # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦ï¼ˆåªæ˜¾ç¤ºéœ€è¦æ›´æ–°çš„è‚¡ç¥¨ï¼‰
            total_to_process = len(stocks_to_update)
            if total_to_process > 0:
                with tqdm(total=total_to_process, desc="æ›´æ–°è¿›åº¦", unit="åª") as pbar:
                    for future in as_completed(future_to_stock):
                        stock_code = future_to_stock[future]
                        try:
                            result_stock, success, records = future.result()
                            if success:
                                if records > 0:
                                    stats['success'] += 1
                                else:
                                    stats['skipped'] += 1
                            else:
                                stats['fail'] += 1
                            stats['new_records'] += records

                        except Exception as e:
                            import traceback
                            tb = traceback.extract_tb(e.__traceback__)
                            if tb:
                                filename, line_number, func_name, text = tb[-1]
                                print(f"å¤„ç†è‚¡ç¥¨ {stock_code} ç»“æœè·å–å¤±è´¥ [{filename}:{line_number}]: {e}")
                            else:
                                print(f"å¤„ç†è‚¡ç¥¨ {stock_code} ç»“æœè·å–å¤±è´¥: {e}")
                            stats['fail'] += 1

                        pbar.update(1)

        return stats

    def _merge_daily_data(self, stock_code: str, new_df: pd.DataFrame) -> bool:
        """åˆå¹¶æ¯æ—¥æ•°æ®"""
        filename = f"{stock_code}_daily.csv"
        filepath = os.path.join(self.daily_dir, filename)

        try:
            # ç¡®ä¿æ–°æ•°æ®æ ¼å¼æ­£ç¡®
            new_df['trade_date'] = pd.to_datetime(new_df['trade_date'], format='%Y%m%d')

            # åŠ è½½ç°æœ‰æ•°æ®
            if os.path.exists(filepath):
                existing_df = pd.read_csv(filepath)
                existing_df['trade_date'] = pd.to_datetime(existing_df['trade_date'], format='%Y%m%d')

                # åˆå¹¶å¹¶å»é‡
                combined = pd.concat([existing_df, new_df], ignore_index=True)
                combined = combined.drop_duplicates(subset=['trade_date'], keep='last')
                combined = combined.sort_values('trade_date')
            else:
                combined = new_df

            # ä¿å­˜æ–‡ä»¶
            combined['trade_date'] = combined['trade_date'].dt.strftime('%Y%m%d')
            combined.to_csv(filepath, index=False, encoding='utf-8-sig')
            return True

        except Exception as e:
            if self.verbose:
                import traceback
                tb = traceback.extract_tb(e.__traceback__)
                if tb:
                    filename, line_number, func_name, text = tb[-1]
                    print(f"åˆå¹¶æ¯æ—¥æ•°æ®å¤±è´¥ {stock_code} [{filename}:{line_number}]: {e}")
                else:
                    print(f"åˆå¹¶æ¯æ—¥æ•°æ®å¤±è´¥ {stock_code}: {e}")
            return False

    def update_all_stocks(self, max_stocks: Optional[int] = None, test_mode: bool = False,
                         parallel: bool = True, max_workers: int = None, force_verbose: bool = False,
                         force_refresh: bool = False, end_date: str = None) -> Dict:
        """
        æ›´æ–°æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®

        Args:
            max_stocks: æœ€å¤§æ›´æ–°è‚¡ç¥¨æ•°é‡ï¼Œç”¨äºæµ‹è¯•
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨æ›´å°çš„APIè¯·æ±‚é—´éš”
            parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼ˆé»˜è®¤Trueï¼‰
            max_workers: æœ€å¤§è¿›ç¨‹æ•°ï¼ˆå¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œé»˜è®¤CPUæ ¸å¿ƒæ•°ä¸€åŠï¼‰
            force_verbose: å¼ºåˆ¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            force_refresh: å¼ºåˆ¶åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜
            end_date: æŒ‡å®šç»“æŸæ—¥æœŸï¼Œå¦‚æœç°æœ‰æ•°æ®å·²è¦†ç›–æ­¤æ—¥æœŸåˆ™è·³è¿‡æ›´æ–°
        """
        print("=" * 70)
        print("Tushareè‚¡ç¥¨æ•°æ®æ›´æ–°å™¨")
        print("=" * 70)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_codes = self.get_stock_list(force_refresh=force_refresh)
        if not stock_codes:
            return {'error': 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨'}

        # é™åˆ¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if max_stocks:
            stock_codes = stock_codes[:max_stocks]
            print(f"âš ï¸ æµ‹è¯•æ¨¡å¼ï¼šåªæ›´æ–°å‰ {max_stocks} åªè‚¡ç¥¨")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_stocks': len(stock_codes),
            'success': 0,
            'fail': 0,
            'skipped': 0,
            'new_records': 0
        }

        print(f"\nå¼€å§‹æ›´æ–° {len(stock_codes)} åªè‚¡ç¥¨çš„æ•°æ®...")

        if parallel and len(stock_codes) > 1:
            # å¹¶è¡Œå¤„ç†
            print("ğŸš€ ä½¿ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼")
            stats = self.update_stocks_parallel(stock_codes, max_workers=max_workers, force_verbose=force_verbose, end_date=end_date)
        else:
            # ä¸²è¡Œå¤„ç†ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
            print("ğŸ”„ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")
            stats = self.update_stocks_serial(stock_codes, test_mode)

        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        self._print_final_report(stats)
        return stats

    def update_stocks_serial(self, stock_codes: List[str], test_mode: bool = False) -> Dict:
        """ä¸²è¡Œæ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåŸå§‹æ–¹æ³•ï¼‰"""
        stats = {
            'total_stocks': len(stock_codes),
            'success': 0,
            'fail': 0,
            'skipped': 0,
            'new_records': 0
        }

        print("=" * 70)

        # æ›´æ–°æ¯åªè‚¡ç¥¨
        for stock_code in tqdm(stock_codes, desc="æ›´æ–°è¿›åº¦", unit="åª"):
            try:
                # æ£€æŸ¥æ•°æ®çŠ¶æ€
                status = self.check_data_status(stock_code)

                # æ›´æ–°æ•°æ®
                if status['needs_update']:
                    if self.update_daily_data(stock_code):
                        stats['success'] += 1
                    else:
                        print(f"âœ— {stock_code} æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
                        stats['fail'] += 1
                else:
                    stats['skipped'] += 1
                    continue

            except Exception as e:
                if self.verbose:
                    import traceback
                    tb = traceback.extract_tb(e.__traceback__)
                    if tb:
                        filename, line_number, func_name, text = tb[-1]
                        print(f"å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™ [{filename}:{line_number}]: {e}")
                    else:
                        print(f"å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}")
                stats['fail'] += 1

            # APIè¯·æ±‚é—´éš”ï¼ˆTushareæœ‰é™æµï¼Œå»ºè®®é—´éš”é•¿ä¸€äº›ï¼‰
            if test_mode:
                time.sleep(0.5)  # æµ‹è¯•æ¨¡å¼0.5ç§’
            else:
                time.sleep(0.5)  # æ­£å¸¸æ¨¡å¼1ç§’

        return stats

    def _print_final_report(self, stats: Dict):
        """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("æ›´æ–°å®ŒæˆæŠ¥å‘Š")
        print("=" * 70)
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ€»è‚¡ç¥¨æ•°: {stats['total_stocks']}")
        print(f"æˆåŠŸæ›´æ–°: {stats['success']}")
        print(f"æ›´æ–°å¤±è´¥: {stats['fail']}")
        print(f"å·²æœ€æ–°: {stats['skipped']}")

        success_rate = (stats['success'] / (stats['success'] + stats['fail'])) * 100 if (stats['success'] + stats['fail']) > 0 else 100
        print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        # æ•°æ®è´¨é‡æ£€æŸ¥
        self._check_data_quality()

        print("=" * 70)

    def _check_data_quality(self):
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        print("\næ•°æ®è´¨é‡æ£€æŸ¥:")

        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ•°é‡
        daily_files = len([f for f in os.listdir(self.daily_dir) if f.endswith('_daily.csv')])

        print(f"  æ•°æ®æ–‡ä»¶æ•°é‡: {daily_files}")

        # æ£€æŸ¥å­˜å‚¨ç©ºé—´
        try:
            total_size = sum(os.path.getsize(os.path.join(self.daily_dir, f))
                           for f in os.listdir(self.daily_dir) if f.endswith('_daily.csv'))

            print(f"  æ•°æ®æ€»å¤§å°: {total_size / 1024 / 1024:.1f} MB")
        except:
            pass

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='Tushareè‚¡ç¥¨æ•°æ®è·å–å™¨')
    parser.add_argument('--max-stocks', type=int, help='æœ€å¤§æ›´æ–°è‚¡ç¥¨æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆåªæ›´æ–°å‰10åªè‚¡ç¥¨ï¼Œè¾ƒçŸ­è¯·æ±‚é—´éš”ï¼‰')
    parser.add_argument('--token', type=str, help='Tushare API tokenï¼ˆä¸»è¦tokenï¼‰')
    parser.add_argument('--tokens', type=str, nargs='+', help='å¤šä¸ªTushare API tokenåˆ—è¡¨ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†é¿å…é™æµï¼‰')
    parser.add_argument('--adjust', type=str, choices=['qfq', 'hfq', ''], default='qfq',
                       help='å¤æƒæ–¹å¼ï¼šqfq-å‰å¤æƒï¼Œhfq-åå¤æƒï¼Œç©ºå­—ç¬¦ä¸²-ä¸å¤æƒï¼ˆé»˜è®¤ï¼šqfqï¼‰')
    parser.add_argument('--parallel', action='store_true', default=True,
                       help='å¯ç”¨å¹¶è¡Œå¤„ç†ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--no-parallel', action='store_true',
                       help='ç¦ç”¨å¹¶è¡Œå¤„ç†ï¼Œä½¿ç”¨ä¸²è¡Œæ¨¡å¼')
    parser.add_argument('--max-workers', type=int, help='æœ€å¤§è¿›ç¨‹æ•°ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼Œé»˜è®¤CPUæ ¸å¿ƒæ•°ä¸€åŠï¼‰')
    parser.add_argument('--verbose', action='store_true', default=False,
                       help='æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†ä¿¡æ¯ï¼ˆå¹¶è¡Œæ¨¡å¼é»˜è®¤å…³é—­ï¼Œä¸²è¡Œæ¨¡å¼é»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--quiet', action='store_true', default=False,
                       help='é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯')
    parser.add_argument('--force-refresh', action='store_true', default=False,
                       help='å¼ºåˆ¶åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ï¼Œé‡æ–°ä»APIè·å–')
    parser.add_argument('--end-date', type=str, help='æŒ‡å®šç»“æŸæ—¥æœŸ(YYYYMMDD)ï¼Œå¦‚æœç°æœ‰æ•°æ®å·²è¦†ç›–æ­¤æ—¥æœŸåˆ™è·³è¿‡æ›´æ–°')

    args = parser.parse_args()

    # è®¾ç½®tokens
    default_tokens = [
        '2d884a7e7c0468f3af578b61146ddb764c2e12a0ccfaf8fbb6d63528',  # åŸæœ‰token
        'bd3a3e286bafb8c1cf602a5eca0e4cf7c2bbeaa28b45e0ab47f260a7'   # æ–°å¢token
    ]

    if args.tokens:
        tokens = args.tokens
    elif args.token:
        tokens = [args.token]
    else:
        tokens = default_tokens

    print(f"ä½¿ç”¨ {len(tokens)} ä¸ªtoken: {[t[:10] + '...' for t in tokens]}")

    # è®¾ç½®verboseæ¨¡å¼
    # å¹¶è¡Œæ¨¡å¼é»˜è®¤ä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆé¿å…è¿›åº¦æ¡å¹²æ‰°ï¼‰ï¼Œä¸²è¡Œæ¨¡å¼é»˜è®¤æ˜¾ç¤º
    is_parallel = args.parallel and not args.no_parallel
    if args.quiet:
        verbose = False
    elif args.verbose:
        verbose = True
    else:
        # é»˜è®¤ï¼šä¸²è¡Œæ¨¡å¼æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼Œå¹¶è¡Œæ¨¡å¼ä¸æ˜¾ç¤º
        verbose = not is_parallel

    # åˆ›å»ºè·å–å™¨
    fetcher = TushareDataFetcher(token=tokens[0], tokens=tokens, adjust=args.adjust, verbose=verbose)

    # å¦‚æœå¼ºåˆ¶è¦æ±‚verboseï¼Œåœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ä¹Ÿæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    force_verbose = args.verbose

    # è®¾ç½®æµ‹è¯•æ¨¡å¼
    max_stocks = args.max_stocks
    if args.test and not max_stocks:
        max_stocks = 10

    # æ‰§è¡Œæ›´æ–°
    parallel = args.parallel and not args.no_parallel
    fetcher.update_all_stocks(
        max_stocks=max_stocks,
        test_mode=args.test,
        parallel=parallel,
        max_workers=args.max_workers,
        force_verbose=force_verbose,
        force_refresh=args.force_refresh,
        end_date=args.end_date
    )

if __name__ == "__main__":
    main()
